fn hist<i: prv, o: prv>(
    h_in: &s shrd cpu.mem [u8; 64*1024],
    h_out: &o uniq cpu.mem [u32; 256]
) -[t: cpu.thread]-> () {
    let mut gpu = gpu_device(0);

    let d_in = gpu_alloc_copy(&uniq gpu, &shrd *h_in);
    let mut d_out = gpu_alloc_copy(&uniq gpu, &shrd *h_out);
    exec::<64, 1024>(
        &uniq gpu,
        (
            &shrd d_in,
            &uniq d_out
        ),
        | inputs: (&shrd gpu.global [u8; 64*1024],
                   &uniq gpu.global [u32; 256])
        | -[grid: gpu.grid<X<64>, X<1024>>]-> () {
            let d_in_groups = group::<1024>(to_view(inputs.0));
            let d_out_atomic = to_atomic_array(inputs.1);
            let d_out_atomic_view = to_view(&shrd *d_out_atomic);

            // TODO shared memory
            // let mut sm_out: [AtomicU32; 256] @ gpu.shared;

            sched block in grid {

                // initialize shared memory histogram
                /*indep(X) 256 block {
                    active => {
                        sched thread in active {
                            atomic_store(&shrd *sm_out_item, 0u32)
                        }
                    },
                    inactive => { () }
                };

                sched thread in block {
                    let tmp = *d_in_item;
                    atomic_fetch_add(&shrd (*sm_out)[tmp], 1u32)
                };*/

                sync;

                indep(X) 256 block {
                    active => {
                        sched thread in active {
                            let d_out_atomic_item = d_out_atomic_view[[thread]];
                            atomic_fetch_add(
                                &shrd *d_out_atomic_item,
                                1u32 //atomic_load( &shrd *sm_out_item )
                            )
                        }
                    },
                    inactive => { () }
                }
            }
        }
    );
    copy_to_host(&shrd d_out, h_out)
}