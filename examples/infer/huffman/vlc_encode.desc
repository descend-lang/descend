fn vlc_encode<s: prv, c: prv, cl: prv, o: prv, oi: prv>(
    h_source_data: &s shrd cpu.mem [u32; 64*256],
    h_codewords: &c shrd cpu.mem [u32; 256],
    h_codewordlens: &cl shrd cpu.mem [u32; 256],
    h_out: &o uniq cpu.mem [u32; 64*256],
    h_out_idx: &oi uniq cpu.mem [u32; 64]
) -[cpu.thread]-> () {
    let mut gpu = gpu_device(0);

    let g_source_data = gpu_alloc_copy(&uniq gpu, &shrd *h_source_data);
    let g_codewords = gpu_alloc_copy(&uniq gpu, &shrd *h_codewords);
    let g_codewordlens = gpu_alloc_copy(&uniq gpu, &shrd *h_codewordlens);
    let mut g_out = gpu_alloc_copy(&uniq gpu, &shrd *h_out);
    let mut g_out_idx = gpu_alloc_copy(&uniq gpu, &shrd *h_out_idx);
    exec::<64, 256>(
        &uniq gpu,
        (
          &shrd g_source_data,
          &shrd g_codewords,
          &shrd g_codewordlens,
          &uniq g_out,
          &uniq g_out_idx
        ),
        | grid: BlockGrp<64, ThreadGrp<256>>,
          inputs: (&shrd gpu.global [u32; 64*256],
                   &shrd gpu.global [u32; 256],
                   &shrd gpu.global [u32; 256],
                   &uniq gpu.global [u32; 64*256],
                   &uniq gpu.global [u32; 64])
        | -[gpu.grid]-> () {
            let g_source_data_block_groups = group::<256>(to_view(inputs.0));
            let g_codewords_view = to_view(inputs.1);
            let g_codewordlens_view = to_view(inputs.2);

            let g_out_block_groups = group_mut::<256>(to_view_mut(inputs.3));
            let g_out_idx_block_groups = group_mut::<1>(to_view_mut(inputs.4));

            decl {
                let mut s_codewords: [u32; 256] @ gpu.shared;
                let mut s_codewordlens: [u32; 256] @ gpu.shared;
                let mut s_result_locations: [u32; 256] @ gpu.shared;
                let mut s_block_out: [AtomicU32; 256] @ gpu.shared;
                let mut s_last_index_to_copy: [u32; 1] @ gpu.shared
            }
            parfor block in grid
            with g_source_data_block_group, g_out_block_group, g_out_idx_block_group
            from g_source_data_block_groups, g_out_block_groups, g_out_idx_block_groups {
                // create shared memory views
                let s_codewords_view = to_view_mut(&uniq s_codewords);
                let s_codewordlens_view = to_view_mut(&uniq s_codewordlens);
                let s_result_locations_view = to_view(&shrd s_result_locations);
                let s_block_out_view = to_view(&shrd s_block_out);
                let s_last_index_to_copy_view = to_view_mut(&uniq s_last_index_to_copy);

                // Declare register variables for information that is relevant throughout the entire
                // algorithm, but can be most efficiently calculated some steps before the
                // information is required.
                // These variables would go out of scope if declared inside "parfor _ in block"!

                // output that is encoded by a single thread
                let mut l_thread_out: u64;

                // length of the output that is encoded by a single thread (in bits)
                let mut l_thread_out_len: u32;

                // index of the value in the output array (32 bits per value) where the output of
                // the current thread starts
                let mut l_thread_start_value: u32;

                // bit-index inside of the value in the output array where the codeword of the
                // current thread starts
                let mut l_thread_start_bit: u32;

                // cache the codewords and their lengths (in bits) in shared memory
                parfor _ in block
                with g_codeword_item, g_codewordlen_item, s_codeword_item, s_codewordlen_item
                from g_codewords_view, g_codewordlens_view, s_codewords_view, s_codewordlens_view {
                    *s_codeword_item = *g_codeword_item;
                    *s_codewordlen_item = *g_codewordlen_item
                };

                // todo syncthreads

                // encode four input symbols per thread and save the total bit-length of the encoded
                // symbols per thread in shared memory
                {
                    let mut s_result_locations_ref = &uniq s_result_locations;
                    let tmp_s_result_locations_view = to_view_mut(&uniq *s_result_locations_ref);
                    parfor _ in block
                    with g_source_data_item , s_result_location_item
                    from g_source_data_block_group , tmp_s_result_locations_view {
                        l_thread_out = 0u64;
                        l_thread_out_len = 0u32;

                        // four symbols are stored in g_source_data_item
                        let tmp_source_data_item = *g_source_data_item;

                        // declare temporary variables
                        let mut tmp_source_data_item_i: u8;
                        let mut tmp_cw: u32;
                        let mut tmp_cwl: u32;

                        // encode first symbol
                        tmp_source_data_item_i = (tmp_source_data_item >> 24) as u8;
                        tmp_cw = s_codewords[tmp_source_data_item_i];
                        tmp_cwl = s_codewordlens[tmp_source_data_item_i];
                        l_thread_out = (l_thread_out<<tmp_cwl) | tmp_cw as u64;
                        l_thread_out_len = l_thread_out_len + tmp_cwl;

                        // encode second symbol
                        tmp_source_data_item_i = (tmp_source_data_item >> 16) as u8;
                        tmp_cw = s_codewords[tmp_source_data_item_i];
                        tmp_cwl = s_codewordlens[tmp_source_data_item_i];
                        l_thread_out = (l_thread_out<<tmp_cwl) | tmp_cw as u64;
                        l_thread_out_len = l_thread_out_len + tmp_cwl;

                        // encode third symbol
                        tmp_source_data_item_i = (tmp_source_data_item >> 8) as u8;
                        tmp_cw = s_codewords[tmp_source_data_item_i];
                        tmp_cwl = s_codewordlens[tmp_source_data_item_i];
                        l_thread_out = (l_thread_out<<tmp_cwl) | tmp_cw as u64;
                        l_thread_out_len = l_thread_out_len + tmp_cwl;

                        // encode fourth symbol
                        tmp_source_data_item_i = tmp_source_data_item as u8;
                        tmp_cw = s_codewords[tmp_source_data_item_i];
                        tmp_cwl = s_codewordlens[tmp_source_data_item_i];
                        l_thread_out = (l_thread_out<<tmp_cwl) | tmp_cw as u64;
                        l_thread_out_len = l_thread_out_len + tmp_cwl;

                        *s_result_location_item = l_thread_out_len
                    }
                };

                // todo syncthreads

                // calculate prefix sum (scan) of thread output lengths
                // (required for position of encoded symbols in output)
                // work-efficient shared memory implementation
                // step 1: up-sweep phase
                {
                    let mut s_result_locations_ref = &uniq s_result_locations;
                    for_nat d in halved_range(128) <'a>{
                        let tmp_up_sweep_view = group_mut::<256/d, 'a, gpu.shared, 256, u32>(
                            to_view_mut(&uniq *s_result_locations_ref
                        ));
                        par_branch split_thread_grp::<d>(block) {
                            active_threads =>
                            parfor _ in active_threads
                            with arr
                            from tmp_up_sweep_view {
                                arr[256/d-1] = arr[256/d-1] + arr[128/d-1]
                            },
                            rest => { () }
                        }
                        // syncthreads
                    }
                };

                // step 2: set last value to zero
                let tmp_view2 = to_view_mut(&uniq s_result_locations);
                let tmp_last = (split uniq (256 - 1) (*tmp_view2)).1;
                par_branch split_thread_grp::<1>(block) {
                    active_thread =>
                    parfor _ in active_thread
                    with last
                    from &uniq *tmp_last {
                        *last = 0u32
                    },
                    rest => { () }
                };

                // syncthreads

                // step 3: down-sweep phase
                {
                    let mut s_result_locations_ref = &uniq s_result_locations;
                    for_nat d in doubled_range(1, 128) <'b>{
                        let tmp_down_sweep_view = group_mut::<256 / d, 'b, gpu.shared, 256, u32>(
                            to_view_mut::<'b, gpu.shared, 256, u32 > (
                                &'b uniq *s_result_locations_ref
                        ));
                        par_branch split_thread_grp::<d>(block) {
                            active_threads =>
                            parfor _ in active_threads
                            with arr
                            from tmp_down_sweep_view {
                                let t = arr[128/d-1];
                                arr[128/d-1] = arr[256/d-1];
                                arr[256/d-1] = arr[256/d-1] + t
                            },
                            rest => { () }
                        }
                        // syncthreads
                    }
                };

                // output the bit-index after the last codeword of the block for every block
                // (g_out_idx_block_item)
                // store the last index of the output that is needed to store the output of the
                // block to reduce the amount of copy operations from gpu.shared to gpu.global
                // (s_last_index_to_copy_item)
                par_branch split_thread_grp::<255>(block) {
                    inactive_threads => { () },
                    active_thread => {
                        parfor _ in active_thread
                        with g_out_idx_block_item, s_last_index_to_copy_item
                        from g_out_idx_block_group, s_last_index_to_copy_view {
                            *g_out_idx_block_item = s_result_locations[255] + l_thread_out_len;
                            *s_last_index_to_copy_item =
                                (s_result_locations[255] + l_thread_out_len) / 32u32
                        }
                    }
                };

                // syncthreads

                // l_thread_start_value =
                //     index of the value in the output array (32 bits per value) where the codeword
                //     of the current thread starts
                // l_thread_start_bit =
                //     bit-index inside of the value in the output array where the codeword of the
                //     current thread starts
                // initialize all values in s_block_out with 0 to use it for storing the output for
                // each block
                parfor _ in block
                with s_result_locations_item, s_block_out_item
                from s_result_locations_view, s_block_out_view {
                    l_thread_start_value = *s_result_locations_item / 32u32;
                    l_thread_start_bit = *s_result_locations_item % 32u32;
                    atomic_store(&shrd *s_block_out_item, 0u32)
                };

                // todo syncthreads

                // combine the output of every thread in a block inside gpu.shared
                // output of a thread can span across 3 32-bit values in gpu.shared!
                parfor _ in block
                with g_out_item, s_block_out_item
                from g_out_block_group, s_block_out_view {
                    let mut wrbits: u32;
                    // Part 1 (first value in gpu.shared)
                    if l_thread_out_len > (32u32 - l_thread_start_bit) {
                        wrbits = (32u32 - l_thread_start_bit)
                    } else {
                        wrbits = l_thread_out_len
                    };
                    let mut tmpcw: u32 = ( l_thread_out >> ( l_thread_out_len - wrbits ) ) as u32;
                    atomic_fetch_or(
                        &shrd (*s_block_out)[l_thread_start_value],
                        tmpcw << (32u32 - l_thread_start_bit - wrbits)
                    );
                    l_thread_out_len = l_thread_out_len - wrbits;

                    // Part 2 (second value in gpu.shared)
                    if l_thread_out_len > 0u32 {
                        if l_thread_out_len > 32u32 {
                            wrbits = 32u32
                        } else {
                            wrbits = l_thread_out_len
                        };
                        l_thread_out_len = l_thread_out_len - wrbits;
                        tmpcw = ( l_thread_out >> l_thread_out_len ) as u32
                                & ( ( 1u32 << wrbits ) - 1u32 );
                        atomic_fetch_or(
                            &shrd (*s_block_out)[l_thread_start_value+1],
                            tmpcw << ( 32u32 - wrbits )
                        );
                        ()
                    };

                    // Part 3 (third value in gpu.shared)
                    if l_thread_out_len > 0u32 {
                        tmpcw = (l_thread_out & ( ( 1u64 << l_thread_out_len) - 1u64) ) as u32;
                        atomic_fetch_or(
                            &shrd (*s_block_out)[l_thread_start_value+2],
                            tmpcw << ( 32u32 - l_thread_out_len )
                        );
                        ()
                    };

                    // todo syncthreads

                    // copy block outputs from gpu.shared to gpu.global
                    if thread_id_x() <= s_last_index_to_copy[0] {
                        *g_out_item = atomic_load(&shrd *s_block_out_item)
                    }
                }
            }
          }
        );
        copy_to_host(&shrd g_out, h_out);
        copy_to_host(&shrd g_out_idx, h_out_idx)
}