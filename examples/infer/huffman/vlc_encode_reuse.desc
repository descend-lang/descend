fn vlc_encode<s: prv, c: prv, cl: prv, o: prv, oi: prv>(
    h_source_data: &s shrd cpu.mem [u32; 64*256],
    h_codewords: &c shrd cpu.mem [u32; 256],
    h_codewordlens: &cl shrd cpu.mem [u32; 256],
    h_out: &o uniq cpu.mem [u32; 64*256],
    h_out_idx: &oi uniq cpu.mem [u32; 64]
) -[t: cpu.thread]-> () {
    let mut gpu = gpu_device(0);

    let g_source_data = gpu_alloc_copy(&uniq gpu, &shrd *h_source_data);
    let g_codewords = gpu_alloc_copy(&uniq gpu, &shrd *h_codewords);
    let g_codewordlens = gpu_alloc_copy(&uniq gpu, &shrd *h_codewordlens);
    let mut g_out = gpu_alloc_copy(&uniq gpu, &shrd *h_out);
    let mut g_out_idx = gpu_alloc_copy(&uniq gpu, &shrd *h_out_idx);
    gpu_vlc_encode::<<<X<64>, X<256>; [u32; 256], [u32; 256], [u32; 256], [u32; 1]>>>(
        &shrd g_source_data,
        &shrd g_codewords,
        &shrd g_codewordlens,
        &uniq g_out,
        &uniq g_out_idx
    );
    copy_to_host(&shrd g_out, h_out);
    copy_to_host(&shrd g_out_idx, h_out_idx)
}


fn gpu_vlc_encode<>(
    g_source_data: &shrd gpu.global [u32; 64*256],
    g_codewords: &shrd gpu.global [u32; 256],
    g_codewordlens: &shrd gpu.global [u32; 256],
    g_out: &uniq gpu.global [u32; 64*256],
    g_out_idx: &uniq gpu.global [u32; 64],
    s_codewords: &uniq gpu.shared [u32; 256],
    s_codewordlens: &uniq gpu.shared [u32; 256],
    s_scan_and_block_out: &uniq gpu.shared [u32; 256],
    s_last_index_to_copy: &uniq gpu.shared [u32; 1]
) -[grid: gpu.grid<X<64>, X<256>>]-> () {
    let g_source_data_block_groups = group::<256>(to_view(g_source_data));
    let g_codewords_view = to_view(g_codewords);
    let g_codewordlens_view = to_view(g_codewordlens);

    let g_out_block_groups = group_mut::<256>(to_view_mut(g_out));
    let g_out_idx_block_groups = group_mut::<1>(to_view_mut(g_out_idx));

    sched block in grid {
        // distribute groups to blocks
        let g_source_data_block_group = g_source_data_block_groups[[block]];
        let g_out_block_group = g_out_block_groups[[block]];
        let g_out_idx_block_group = g_out_idx_block_groups[[block]];

        // Declare register variables for information that is relevant throughout the entire
        // algorithm, but can be most efficiently calculated some steps before the
        // information is required.
        // These variables would go out of scope if declared inside "sched thread in block"!

        // output that is encoded by a single thread
        let mut l_thread_out: u64 = 0u64;

        // length of the output that is encoded by a single thread (in bits)
        let mut l_thread_out_len: u32 = 0u32;

        // index of the value in the output array (32 bits per value) where the output of
        // the current thread starts
        let mut l_thread_start_value: u32 = 0u32; // does not need to be initialized here

        // bit-index inside of the value in the output array where the codeword of the
        // current thread starts
        let mut l_thread_start_bit: u32 = 0u32; // does not need to be initialized here

        // cache the codewords and their lengths (in bits) in shared memory
        {
            let s_codewords_view = to_view_mut(&uniq *s_codewords);
            let s_codewordlens_view = to_view_mut(&uniq *s_codewordlens);
            sched thread in block {
                let g_codeword_item = g_codewords_view[[thread]];
                let g_codewordlen_item = g_codewordlens_view[[thread]];
                let s_codeword_item = s_codewords_view[[thread]];
                let s_codewordlen_item = s_codewordlens_view[[thread]];

                *s_codeword_item = *g_codeword_item;
                *s_codewordlen_item = *g_codewordlen_item
            }
        };

        sync;

        // encode four input symbols per thread and save the total bit-length of the encoded
        // symbols per thread in shared memory
        {
            let mut s_scan_ref = &uniq *s_scan_and_block_out;
            let tmp_s_scan_view = to_view_mut(&uniq *s_scan_ref);
            sched thread in block {
                let g_source_data_item = g_source_data_block_group[[thread]];
                let s_scan_item = tmp_s_scan_view[[thread]];

                // four symbols are stored in g_source_data_item
                let tmp_source_data_item = *g_source_data_item;

                // declare temporary variables
                let mut tmp_source_data_item_i: u8;
                let mut tmp_cw: u32;
                let mut tmp_cwl: u32;

                // encode first symbol
                tmp_source_data_item_i = (tmp_source_data_item >> 24) as u8;
                tmp_cw = s_codewords[tmp_source_data_item_i];
                tmp_cwl = s_codewordlens[tmp_source_data_item_i];
                l_thread_out = (l_thread_out<<tmp_cwl) | tmp_cw as u64;
                l_thread_out_len = l_thread_out_len + tmp_cwl;

                // encode second symbol
                tmp_source_data_item_i = (tmp_source_data_item >> 16) as u8;
                tmp_cw = s_codewords[tmp_source_data_item_i];
                tmp_cwl = s_codewordlens[tmp_source_data_item_i];
                l_thread_out = (l_thread_out<<tmp_cwl) | tmp_cw as u64;
                l_thread_out_len = l_thread_out_len + tmp_cwl;

                // encode third symbol
                tmp_source_data_item_i = (tmp_source_data_item >> 8) as u8;
                tmp_cw = s_codewords[tmp_source_data_item_i];
                tmp_cwl = s_codewordlens[tmp_source_data_item_i];
                l_thread_out = (l_thread_out<<tmp_cwl) | tmp_cw as u64;
                l_thread_out_len = l_thread_out_len + tmp_cwl;

                // encode fourth symbol
                tmp_source_data_item_i = tmp_source_data_item as u8;
                tmp_cw = s_codewords[tmp_source_data_item_i];
                tmp_cwl = s_codewordlens[tmp_source_data_item_i];
                l_thread_out = (l_thread_out<<tmp_cwl) | tmp_cw as u64;
                l_thread_out_len = l_thread_out_len + tmp_cwl;

                *s_scan_item = l_thread_out_len
            }
        };

        sync;

        // calculate exclusive prefix sum (scan) of thread output lengths
        // (required for position of encoded symbols in output)
        // work-efficient shared memory implementation
        // step 1: up-sweep phase
        {
            let mut s_scan_ref = &uniq *s_scan_and_block_out;
            for_nat d in halved_range(128) <'a>{
                let tmp_up_sweep_view = group_mut::<256/d, 'a, gpu.shared, 256, u32>(
                    to_view_mut(&uniq *s_scan_ref)
                );
                indep(X) d block {
                    active_threads => {
                        sched thread in active_threads {
                            let arr = tmp_up_sweep_view[[thread]];
                            arr[256 / d - 1] = arr[256 / d - 1] + arr[128 / d - 1]
                        }
                    },
                    rest => { () }
                };
                sync
            }
        };

        // step 2: set last value to zero
        {
            let tmp_view2 = to_view_mut(&uniq *s_scan_and_block_out);
            let tmp_last = (split uniq (256 - 1) (*tmp_view2)).1;
            indep(X) 1 block {
                active_thread => {
                    sched thread in active_thread {
                        let tmp_last_borrow = &uniq *tmp_last;
                        let last = tmp_last_borrow[[thread]];

                        *last = 0u32
                    }
                },
                rest => { () }
            }
        };

        sync;

        // step 3: down-sweep phase
        {
            let mut s_scan_ref = &uniq *s_scan_and_block_out;
            for_nat d in doubled_range(1, 128) <'b>{
                let tmp_down_sweep_view = group_mut::<256 / d, 'b, gpu.shared, 256, u32>(
                    to_view_mut::<'b, gpu.shared, 256, u32 >(
                        &'b uniq *s_scan_ref
                ));
                indep(X) d block {
                    active_threads => {
                        sched thread in active_threads {
                            let arr = tmp_down_sweep_view[[thread]];

                            let t = arr[128/d-1];
                            arr[128/d-1] = arr[256/d-1];
                            arr[256/d-1] = arr[256/d-1] + t
                        }
                    },
                    rest => { () }
                };
                sync
            }
        };

        // output the bit-index after the last codeword of the block for every block
        // (g_out_idx_block_item)
        // store the last index of the output that is needed to store the output of the
        // block to reduce the amount of copy operations from gpu.shared to gpu.global
        // (s_last_index_to_copy_item)
        {
            let s_scan_and_block_out_view = to_view(&shrd *s_scan_and_block_out);
            let s_last_index_to_copy_view = to_view_mut(&uniq *s_last_index_to_copy);
            indep(X) 255 block {
                inactive_threads => { () },
                active_thread => {
                    sched thread in active_thread {
                        let g_out_idx_block_item = g_out_idx_block_group[[thread]];
                        let s_last_index_to_copy_item = s_last_index_to_copy_view[[thread]];

                        *g_out_idx_block_item = s_scan_and_block_out[255] + l_thread_out_len;
                        *s_last_index_to_copy_item =
                            (s_scan_and_block_out[255] + l_thread_out_len) / 32u32
                    }
                }
            }
        };

        sync;

        // l_thread_start_value =
        //     index of the value in the output array (32 bits per value) where the codeword
        //     of the current thread starts
        // l_thread_start_bit =
        //     bit-index inside of the value in the output array where the codeword of the
        //     current thread starts
        // initialize all values in s_scan_and_block_out with 0 to use it for storing the
        // output for each block
        {
            let s_scan_and_block_out_view = to_view_mut(&uniq *s_scan_and_block_out);
            sched thread in block {
                let s_scan_and_block_out_item = s_scan_and_block_out_view[[thread]];

                l_thread_start_value = *s_scan_and_block_out_item / 32u32;
                l_thread_start_bit = *s_scan_and_block_out_item % 32u32;
                *s_scan_and_block_out_item = 0u32
            }
        };

        sync;

        // combine the output of every thread in a block inside gpu.shared
        // output of a thread can span across 3 32-bit values in gpu.shared!
        {
            let mut s_block_out = to_atomic_array(&uniq *s_scan_and_block_out);
            sched thread in block {
                let mut wrbits: u32;
                // Part 1 (first value in gpu.shared)
                if l_thread_out_len > (32u32 - l_thread_start_bit) {
                    wrbits = (32u32 - l_thread_start_bit)
                } else {
                    wrbits = l_thread_out_len
                };
                let mut tmpcw: u32 = ( l_thread_out >> ( l_thread_out_len - wrbits ) ) as u32;
                atomic_fetch_or(
                    &shrd (*s_block_out)[l_thread_start_value],
                    tmpcw << (32u32 - l_thread_start_bit - wrbits)
                );
                l_thread_out_len = l_thread_out_len - wrbits;

                // Part 2 (second value in gpu.shared)
                if l_thread_out_len > 0u32 {
                    if l_thread_out_len > 32u32 {
                        wrbits = 32u32
                    } else {
                        wrbits = l_thread_out_len
                    };
                    l_thread_out_len = l_thread_out_len - wrbits;
                    tmpcw = ( l_thread_out >> l_thread_out_len ) as u32
                            & ( ( 1u32 << wrbits ) - 1u32 );
                    atomic_fetch_or(
                        &shrd (*s_block_out)[l_thread_start_value+1],
                        tmpcw << ( 32u32 - wrbits )
                    );
                    ()
                };

                // Part 3 (third value in gpu.shared)
                if l_thread_out_len > 0u32 {
                    tmpcw = (l_thread_out & ( ( 1u64 << l_thread_out_len) - 1u64) ) as u32;
                    atomic_fetch_or(
                        &shrd (*s_block_out)[l_thread_start_value+2],
                        tmpcw << ( 32u32 - l_thread_out_len )
                    );
                    ()
                }
            }
        };

        sync;

        {
            let s_scan_and_block_out_view = to_view(&shrd *s_scan_and_block_out);
            sched thread in block {
                let g_out_item = g_out_block_group[[thread]];
                let s_block_out_item = s_scan_and_block_out_view[[thread]];
                // copy block outputs from gpu.shared to gpu.global
                if thread_id_x() <= s_last_index_to_copy[0] {
                    *g_out_item = *s_block_out_item
                }
            }
        }
    }
}