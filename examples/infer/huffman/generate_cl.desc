fn generate_cl<
    mblocks: nat,
    nz_dict_size: nat,
    h: prv,
    c: prv,
    lnf: prv,
    lnl: prv,
    inf: prv,
    inl: prv,
    tf: prv,
    til: prv,
    ti: prv,
    cf: prv,
    cil: prv,
    ci: prv,
    dpi: prv
>(
    h_histogram: &h uniq cpu.mem [u32; nz_dict_size],
    h_CL: &c uniq cpu.mem [u32; nz_dict_size],
    h_lNodesFreq: &lnf uniq cpu.mem [u32; nz_dict_size],
    h_lNodesLeader: &lnl uniq cpu.mem [i32; nz_dict_size],
    h_iNodesFreq: &inf uniq cpu.mem [u32; nz_dict_size],
    h_iNodesLeader: &inl uniq cpu.mem [i32; nz_dict_size],
    h_tempFreq: &tf uniq cpu.mem [u32; nz_dict_size],
    h_tempIsLeaf: &til uniq cpu.mem [i32; nz_dict_size],
    h_tempIndex: &ti uniq cpu.mem [i32; nz_dict_size],
    h_copyFreq: &cf uniq cpu.mem [u32; nz_dict_size],
    h_copyIsLeaf: &cil uniq cpu.mem [i32; nz_dict_size],
    h_copyIndex: &ci uniq cpu.mem [i32; nz_dict_size],
    h_diagonal_path_intersections: &dpi uniq cpu.mem [u32; nz_dict_size]
) -[cpu.thread]-> () {
    let mut gpu = gpu_device(0);

    let mut g_histogram = gpu_alloc_copy(&uniq gpu, &shrd *h_histogram);
    let mut g_CL = gpu_alloc_copy(&uniq gpu, &shrd *h_CL);
    let mut g_lNodesFreq = gpu_alloc_copy(&uniq gpu, &shrd *h_lNodesFreq);
    let mut g_lNodesLeader = gpu_alloc_copy(&uniq gpu, &shrd *h_lNodesLeader);
    let mut g_iNodesFreq = gpu_alloc_copy(&uniq gpu, &shrd *h_iNodesFreq);
    let mut g_iNodesLeader = gpu_alloc_copy(&uniq gpu, &shrd *h_iNodesLeader);
    let mut g_tempFreq = gpu_alloc_copy(&uniq gpu, &shrd *h_tempFreq);
    let mut g_tempIsLeaf = gpu_alloc_copy(&uniq gpu, &shrd *h_tempIsLeaf);
    let mut g_tempIndex = gpu_alloc_copy(&uniq gpu, &shrd *h_tempIndex);
    let mut g_copyFreq = gpu_alloc_copy(&uniq gpu, &shrd *h_copyFreq);
    let mut g_copyIsLeaf = gpu_alloc_copy(&uniq gpu, &shrd *h_copyIsLeaf);
    let mut g_copyIndex = gpu_alloc_copy(&uniq gpu, &shrd *h_copyIndex);
    let mut g_diagonal_path_intersections = gpu_alloc_copy(&uniq gpu, &shrd *h_diagonal_path_intersections);

    exec::<mblocks, 32>(
        &uniq gpu,
    (
        &uniq g_histogram,
        &uniq g_CL,
        &uniq g_lNodesFreq,
        &uniq g_lNodesLeader,
        &uniq g_iNodesFreq,
        &uniq g_iNodesLeader,
        &uniq g_tempFreq,
        &uniq g_tempIsLeaf,
        &uniq g_tempIndex,
        &uniq g_copyFreq,
        &uniq g_copyIsLeaf,
        &uniq g_copyIndex,
        &uniq g_diagonal_path_intersections
    ),
    | grid: BlockGrp<mblocks, ThreadGrp<32>>,
    inputs: (&uniq gpu.global [u32; nz_dict_size],
        &uniq gpu.global [u32; nz_dict_size],
        &uniq gpu.global [u32; nz_dict_size],
        &uniq gpu.global [i32; nz_dict_size],
        &uniq gpu.global [u32; nz_dict_size],
        &uniq gpu.global [i32; nz_dict_size],
        &uniq gpu.global [u32; nz_dict_size],
        &uniq gpu.global [i32; nz_dict_size],
        &uniq gpu.global [i32; nz_dict_size],
        &uniq gpu.global [u32; nz_dict_size],
        &uniq gpu.global [i32; nz_dict_size],
        &uniq gpu.global [i32; nz_dict_size],
        &uniq gpu.global [u32; nz_dict_size])
    | -[gpu.grid]-> () {

        // declare shared memory
        /*decl {
            let mut sm_x_top: [u32; 1] @ gpu.shared;
            let mut sm_y_top: [u32; 1] @ gpu.shared;
            let mut sm_x_bottom: [u32; 1] @ gpu.shared;
            let mut sm_y_bottom: [u32; 1] @ gpu.shared;
            let mut sm_found: [u32; 1] @ gpu.shared;
            let mut sm_oneorzero: [u32; 32] @ gpu.shared
        };*/

        // declare local memory
        let mut l_iNodesFront: i32;
        let mut l_iNodesRear: i32;
        let mut l_lNodesCur: i32;
        let mut l_iNodesSize: i32;
        let mut l_curLeavesNum: i32;
        let mut l_minFreq: i32;
        let mut l_tempLength: i32;
        let mut l_mergeFront: i32;
        let mut l_mergeRear: i32;
        let mut l_lNodesIndex: i32;

        let g_CL_groups = group_mut::<32>(to_view_mut(inputs.1));
        let g_lNodesLeader_groups = group_mut::<32>(to_view_mut(inputs.3));

        parfor block in grid
        with g_CL_group, g_lNodesLeader_group
        from g_CL_groups, g_lNodesLeader_groups {

            parfor _ in block
            with g_CL_item, g_lNodesLeader_item
            from g_CL_group, g_lNodesLeader_group {
                *g_CL_item = 0u32;
                *g_lNodesLeader_item = -1i32
            };

            par_branch split_thread_grp::<1>(block) {
                active_thread => {
                    if /* block_id_x() statt */ 0 == 0 {
                        l_iNodesFront = 0;
                        l_iNodesRear = 0;
                        l_lNodesCur = 0;
                        l_iNodesSize = 0
                    }
                },
                rest => { () }
            }

        };

        //grid sync

        while (l_lNodesCur < nz_dict_size || l_iNodesSize > 1) {

            parfor block in split_block_grp::<1>(grid)
            with _
            from _ {
                par_branch split_thread_grp::<1>(block) {
                    active_thread => {
                        if /* block_id_x() statt */ 0 == 0 {
                            let mut l_t_midFreq: [u32; 4];
                            let mut l_t_midIsLeaf: [i32; 4];
                            for_nat i in range(0,4) {
                                l_t_midFreq[i] = 4294967295u32
                            };
                            if (l_lNodesCur < nz_dict_size) {
                                l_t_midFreq[0] = l
                            }
                        }
                    },
                    rest => { () }
                }
            }

        }
    }
    )

}