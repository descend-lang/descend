// //#define TILE_SIZE 16 //so noch nicht möglich
//
fn lud_descend<tile_size: nat, matrix_dim: nat, r:prv>(
    m5: &r uniq cpu.mem [f32; matrix_dim * matrix_dim]
) -[t: cpu.thread]-> ()
{
    let mut gpu = gpu_device(0);
    let mut m_gpu = gpu_alloc_copy(&uniq gpu, &shrd *m5);

    for_nat it in 0..(matrix_dim/tile_size-1) {

        //1-D Grid mit 1-D Threads
        lud_diagonal::<<<X<1>, X<tile_size>; [f32; tile_size * tile_size]>>>::<it, tile_size, matrix_dim>(&uniq m_gpu);

         lud_perimeter::<<<X<matrix_dim/tile_size-it-1>, X<tile_size*2>; [f32; tile_size * tile_size], [f32; tile_size * tile_size], [f32; tile_size * tile_size]>>>
             ::<it, tile_size, matrix_dim>(&uniq m_gpu);

        lud_internal::<<<XY<matrix_dim/tile_size-it-1, matrix_dim/tile_size-it-1>, XY<tile_size, tile_size>;
           [f32; tile_size * tile_size] ,  [f32; tile_size * tile_size]>>>::<it, tile_size, matrix_dim>(&uniq m_gpu)
        };

    lud_diagonal::<<<X<1>, X<tile_size>; [f32; tile_size * tile_size]>>>::<(matrix_dim/tile_size)-1, tile_size, matrix_dim>(&uniq m_gpu); //::<(matrix_dim/tile_size) ,tile_size, matrix_dim>

    copy_to_host(&shrd m_gpu, m5)
}


fn lud_diagonal<it:nat, tile_size: nat, matrix_dim: nat, r: prv, p: prv>(
    m: &r uniq gpu.global [f32; matrix_dim * matrix_dim],
    local_tile: &p uniq gpu.shared [f32; tile_size * tile_size]
) -[grid: gpu.grid<X<1>, X<tile_size>>]-> ()
{
    //let tiles_per_dim = matrix_dim / tile_size;
    let matrix_view: &uniq gpu.global [[ [[ [[ [[f32; tile_size]]; tile_size]]; (matrix_dim / tile_size)]]; (matrix_dim / tile_size) ]] = &uniq (*m).to_view.grp::<matrix_dim>.grp::<tile_size>.map::<[[ [[f32; matrix_dim]]; tile_size]]>(transp).map::<[[ [[f32; tile_size]]; matrix_dim]]>(grp::<tile_size>).map::<[[ [[ [[f32; tile_size]]; tile_size]]; matrix_dim/tile_size]]>(map::<[[ [[f32; tile_size]]; tile_size]]>(transp));
        //&uniq (*m).to_view.grp::<tile_size>.map::<[[ [f32; matrix_dim]; tile_size]]>(map::<[f32; matrix_dim]>(to_view).transp.grp::<tile_size>.map::<[[ [[f32; tile_size]]; tile_size]]>(transp));

    //Berechnung des Diagonal tiles
    let row_of_tiles: &uniq gpu.global [[ [[ [[f32; tile_size]]; tile_size]]; (matrix_dim / tile_size) ]]= &uniq (*matrix_view)[it];
    let tile: &uniq gpu.global [[ [[f32; tile_size]]; tile_size]] = &uniq (*row_of_tiles)[..it..].1[0];

    let local_tile_view: &uniq gpu.shared [[ [[f32; tile_size]]; tile_size]] = &uniq (*local_tile).to_view.grp::<tile_size>; //wenn lokaler speicher wieder mehrdimensional: .map::<[[ [f32; tile_size]; tile_size]]>(map::<[f32; tile_size]>(to_view))

    sched block in grid {// m: &uniq [[ [[f32; tile_size]]; tile_size]]
        //let tile: &uniq gpu.global [[ [[f32; tile_size]]; tile_size]] = &uniq (*position_of_tile)[[block]];

        sched thread in block { //TODO kann so aliasing benutzt werden zur Optimierung?
            let global_thread_tile: &uniq gpu.global [[f32;tile_size]] = &uniq (*tile).transp[[thread]];
            let local_thread_tile: &uniq gpu.shared [[f32;tile_size]] = &uniq (*local_tile_view).transp[[thread]];

            for_nat i in 0..tile_size {
                (*local_thread_tile)[i] = (*global_thread_tile)[i]
            }
        };
        sync;

        for_nat i in 0..(tile_size-1) {
            //disjunkte partitionierung erstellen für threads
            let mat_view_partition: &uniq gpu.shared ([[ [[f32; tile_size]]; i+1]], [[ [[f32; tile_size]]; tile_size-(i+1)]]) = &uniq (*local_tile_view)[..i+1..]; //ab i+1-te Zeile abschneiden: (&shrd [[ [[f32; tile_size]]; i+1]], &shrd [[ [[f32; tile_size]]; tile_size - (i+1)]]) -> (Zeile 0..i, Zeile i+1...ende)

            // -> zugriff auf row.0 mit schleifenvariable i möglich für i-te Spalte für gemeinsamen Zugriff

            //1.transpose von row.1 -> für das Splitten an der richtigen Stelle
            //2.split -> so splitten das 0..i in dem 1. teil des tupels sind
            //3.transpose -> damit die Zeilen passend zu den thread_elementen auf die threads verteilt werden
            {
                let rhs_tile_transposed: &uniq gpu.shared [[ [[f32; tile_size - (i +1)]]; tile_size]] = &uniq (*mat_view_partition).1.transp;

                let split_column: &uniq gpu.shared  ([[ [[f32; tile_size - (i + 1)]]; i]], [[ [[f32; tile_size -(i + 1)]]; tile_size -i]]) = &uniq (*rhs_tile_transposed)[..i..];
                let thread_elements: &uniq gpu.shared [[f32; tile_size - (i + 1)]] = &uniq (*split_column).1[0];

                //für indiviuelle Zugriffe: -> die nicht veränderbar sein sollen
                let indiv_access: &shrd gpu.shared [[ [[f32; i]]; tile_size - (i+ 1)]] = &shrd (*split_column).0.transp;

                let column_i: &shrd gpu.shared [[f32; i+1]] = &shrd (*mat_view_partition).0.transp[i];

                indep(X) (i+1) block { //elem: &uniq f32, shrd_row: &shrd [[f32, i]]
                    active_threads => {
                        ()
                    },
                    inactive_threads => {
                        sched thread in inactive_threads {
                            let elem: &uniq gpu.shared f32 = &uniq (*thread_elements)[[thread]];
                            let shrd_row: &shrd gpu.shared [[f32; i]] = &shrd (*indiv_access)[[thread]];
                            for_nat j in 0..i {
                                *elem = (*elem) - ((*shrd_row)[j] * (*column_i)[j])
                            };
                            *elem = (*elem) / (*column_i)[i]
                        }
                    }
                };
                sync
            };
            //2. Berechnung
            //Elemente [i+1, i+1],..., [i+1, tile_size]
            let row_i1: &uniq gpu.shared [[f32; tile_size]] = &uniq (*mat_view_partition).1[0];
            let split_row_i1: &uniq gpu.shared ([[f32; i+1]], [[f32; tile_size-(i+1)]])  = &uniq (*row_i1)[..i+1..]; //-> (0..i, i+1..ende)
            let thread_elements: &uniq gpu.shared [[f32; tile_size-(i+1)]] = &uniq (*split_row_i1).1;
            let shrd_row: &shrd gpu.shared [[f32; i+1]] = &shrd (*split_row_i1).0;

            //(shrd_row_access, thread_elements):
            let indiv_access: &shrd gpu.shared [[ [[f32; i+1]]; tile_size-(i+1)]]  = &shrd (*mat_view_partition).0.transp[..i+1..].1;

            indep(X) (i+1) block  {
                active_threads => { () },
                inactive_threads => {
                    sched thread in inactive_threads {
                        let elem: &uniq gpu.shared f32  = &uniq (*thread_elements)[[thread]];
                        let shrd_column: &shrd gpu.shared [[f32; i+1]] = &shrd (*indiv_access)[[thread]];
                        for_nat j in 0..(i+1) {
                            *elem = *elem - ((*shrd_row)[j] * (*shrd_column)[j])
                        }
                    }
                }
            };
            sync
        };

        sched thread in block { //TODO kann so aliasing benutzt werden zur Optimierung?
            let global_thread_tile: &uniq gpu.global [[f32;tile_size]] = &uniq (*tile).transp[[thread]];
            let local_thread_tile: &uniq gpu.shared [[f32;tile_size]] = &uniq (*local_tile_view).transp[[thread]];

            for_nat i in 1..tile_size {
                (*global_thread_tile)[i] = (*local_thread_tile)[i]
            }
        }
    }
}



fn lud_perimeter<it:nat, tile_size: nat, matrix_dim: nat, r: prv, a: prv, b: prv, c: prv>(
    m2: &r uniq gpu.global [f32; matrix_dim * matrix_dim],
    peri_row: &a uniq gpu.shared [f32; tile_size * tile_size],
    peri_col: &b uniq gpu.shared [f32; tile_size * tile_size],
    dia: &c uniq gpu.shared [f32; tile_size * tile_size]
) -[grid: gpu.grid<X<matrix_dim/tile_size-it-1>, X<tile_size*2>>]-> ()
{
    let matrix_view: &uniq gpu.global [[ [[ [[ [[f32; tile_size]]; tile_size]]; (matrix_dim / tile_size)]]; (matrix_dim / tile_size) ]] =
        &uniq (*m2).to_view.grp::<matrix_dim>.grp::<tile_size>.map::<[[ [[f32; matrix_dim]]; tile_size]]>(transp).map::<[[ [[f32; tile_size]]; matrix_dim]]>(grp::<tile_size>).map::<[[ [[ [[f32; tile_size]]; tile_size]]; matrix_dim/tile_size]]>(map::<[[ [[f32; tile_size]]; tile_size]]>(transp));

    //Berechnung der Äußeren Tiles und des Diagonal-Tiles
    //(row_of_tiles, rest) -> row_of_tiles for position of dia and peri_row, rest is for position of peri_col
    let splitted_row_of_tiles_and_rest: &uniq gpu.global ([[ [[ [[ [[f32; tile_size]]; tile_size]]; (matrix_dim / tile_size) ]]; 1]], [[ [[ [[ [[f32; tile_size]]; tile_size]]; (matrix_dim / tile_size)]]; matrix_dim/tile_size -it-1]]) =
            &uniq (*matrix_view)[..it..].1[..1..];
    //(dia, peri_row) in global
    let position_of_tile: &uniq gpu.global ([[ [[ [[f32; tile_size]]; tile_size]]; 1]], [[ [[ [[f32; tile_size]]; tile_size]]; matrix_dim/tile_size -it-1]])  =
           &uniq (*splitted_row_of_tiles_and_rest).0[0][..it..].1[..1..];
    let dia_global: &shrd gpu.global [[ [[f32; tile_size]]; tile_size]] = &shrd (*position_of_tile).0[0];
    let peri_row_global: &uniq gpu.global [[ [[ [[f32; tile_size]]; tile_size]]; matrix_dim/tile_size -it-1]] = &uniq (*position_of_tile).1;

    // //peri_col in global TODO merken für innere Tiles: (*splitted_row_of_tiles_and_rest).1.transp[..it..].1[..1..].1 noch zurück transponieren -> inneres tranpose rückgängig machen
    let peri_col_global: &uniq gpu.global [[ [[ [[f32; tile_size]]; tile_size]]; matrix_dim/tile_size - it-1]] =
            &uniq (*splitted_row_of_tiles_and_rest).1.transp[..it..].1[..1..].0[0];
    //
    // //create shared views
    let dia_view: &uniq gpu.shared [[ [[f32; tile_size]]; tile_size]] = &uniq (*dia).to_view.grp::<tile_size>;//.map::<[[f32; tile_size]; tile_size]>(to_view.map::<[f32; tile_size]>(to_view));
    let peri_row_view: &uniq gpu.shared [[ [[f32; tile_size]]; tile_size]] = &uniq (*peri_row).to_view.grp::<tile_size>;//.map::<[[f32; tile_size]; tile_size]>(to_view.map::<[f32; tile_size]>(to_view));
    let peri_col_view: &uniq gpu.shared [[ [[f32; tile_size]]; tile_size]] = &uniq (*peri_col).to_view.grp::<tile_size>;//.map::<[[f32; tile_size]; tile_size]>(to_view.map::<[f32; tile_size]>(to_view));

    sched block in grid {
        let peri_row_global_tile: &uniq gpu.global [[ [[f32; tile_size]]; tile_size]] = &uniq (*peri_row_global)[[block]];
        let peri_col_global_tile: &uniq gpu.global [[ [[f32; tile_size]]; tile_size]] = &uniq (*peri_col_global)[[block]];

        let split_dia_tile: &uniq gpu.shared ([[ [[f32; tile_size]]; tile_size/2]], [[ [[f32; tile_size]]; tile_size-tile_size/2]]) = &uniq (*dia_view)[..tile_size/2..];
        let split_dia_global: &shrd gpu.global ([[ [[f32; tile_size]]; tile_size/2]], [[ [[f32; tile_size]]; tile_size-tile_size/2]]) = &shrd (*dia_global)[..tile_size/2..];

        indep(X) tile_size block {
            active_threads => {
                sched thread in active_threads {
                    let peri_row_global_tile_thread: &uniq gpu.global [[f32; tile_size]] = &uniq (*peri_row_global_tile).transp[[thread]];
                    let peri_row_shared_tile_thread: &uniq gpu.shared [[f32; tile_size]] = &uniq (*peri_row_view).transp[[thread]];
                    let dia_tile_thread: &uniq gpu.shared [[f32; tile_size/2]] = &uniq ((*split_dia_tile).0.transp)[[thread]];
                    let dia_global_thread: &shrd gpu.global [[f32; tile_size/2]] = &shrd ((*split_dia_global).0.transp)[[thread]];

                    for_nat i in 0..tile_size/2 {
                        (*dia_tile_thread)[i] = (*dia_global_thread)[i]
                    };

                    for_nat i in 0..tile_size {
                        (*peri_row_shared_tile_thread)[i] = (*peri_row_global_tile_thread)[i]
                    }
                }
            },
            inactive_threads => {
                sched thread in inactive_threads {
                    let peri_col_global_tile_thread: &uniq gpu.global [[f32; tile_size]] = &uniq (*peri_col_global_tile).transp[[thread]];
                    let peri_col_shared_tile_thread: &uniq gpu.shared [[f32; tile_size]] = &uniq (*peri_col_view).transp[[thread]];
                    let dia_tile_thread: &uniq gpu.shared [[f32; tile_size-tile_size/2]] = &uniq ((*split_dia_tile).1.transp)[[thread]];
                    let dia_global_thread: &shrd gpu.global [[f32; tile_size-tile_size/2]] = &shrd ((*split_dia_global).1.transp)[[thread]];

                    for_nat i in 0..(tile_size-tile_size/2) {
                        (*dia_tile_thread)[i] = (*dia_global_thread)[i]
                    };

                    for_nat i in 0..tile_size {
                        (*peri_col_shared_tile_thread)[i] = (*peri_col_global_tile_thread)[i]
                    }
                }
            }
        };
        sync;
        let peri_row_transp:  &uniq gpu.shared [[ [[f32; tile_size]]; tile_size]] = &uniq (*peri_row_view).transp;
        indep(X) tile_size block {
            active_threads => {
                sched thread in active_threads {
                    let peri_row_column: &uniq gpu.shared [[f32; tile_size]] = &uniq (*peri_row_transp)[[thread]];
                    for_nat i in 1..tile_size {
                        for_nat j in 0..i {
                            (*peri_row_column)[i] = (*peri_row_column)[i] - (*dia_view)[i][j] * (*peri_row_column)[j]
                        }
                    }
                }
            },
            inactive_threads => {
                sched thread in inactive_threads {
                    let peri_col_row: &uniq gpu.shared [[f32; tile_size]] = &uniq (*peri_col_view)[[thread]];
                    for_nat i in 0..tile_size {
                        for_nat j in 0..i {
                            (*peri_col_row)[i] = (*peri_col_row)[i] - (*dia_view)[j][i] * (*peri_col_row)[j]
                        };
                        (*peri_col_row)[i] = (*peri_col_row)[i] / (*dia_view)[i][i]
                    }
                }
            }
        };
        sync;

        indep(X) tile_size block {
            active_threads => {
                sched thread in active_threads {
                    let peri_row_global_tile_thread: &uniq gpu.global [[f32; tile_size]] = &uniq (*peri_row_global_tile).transp[[thread]];
                    let peri_row_shared_tile_thread: &uniq gpu.shared [[f32; tile_size]] = &uniq (*peri_row_view).transp[[thread]];

                    for_nat i in 1..tile_size {
                        (*peri_row_global_tile_thread)[i] = (*peri_row_shared_tile_thread)[i]
                    }
                }
            },
            inactive_threads => {
                sched thread in inactive_threads {
                    let peri_col_global_tile_thread: &uniq gpu.global [[f32; tile_size]] =  &uniq (*peri_col_global_tile).transp[[thread]];
                    let peri_col_shared_tile_thread: &uniq gpu.shared [[f32; tile_size]] =  &uniq (*peri_col_view).transp[[thread]];

                    for_nat i in 0..tile_size {
                        (*peri_col_global_tile_thread)[i] = (*peri_col_shared_tile_thread)[i]
                    }
                }
            }
        }
    }
}


fn lud_internal<it:nat, tile_size: nat, matrix_dim: nat, r:prv, a: prv, b:prv>(
    m3: &r uniq gpu.global [f32; matrix_dim * matrix_dim],
    peri_row: &a uniq gpu.shared [f32; tile_size * tile_size],
    peri_col: &b uniq gpu.shared [f32; tile_size * tile_size]
) -[grid: gpu.grid<XY<matrix_dim/tile_size-it-1, matrix_dim/tile_size-it-1>, XY<tile_size, tile_size>>]-> ()
{
    let matrix_view: &uniq gpu.global [[ [[ [[ [[f32; tile_size]]; tile_size]]; (matrix_dim / tile_size)]]; (matrix_dim / tile_size) ]] =
            &uniq (*m3).to_view.grp::<matrix_dim>.grp::<tile_size>.map::<[[ [[f32; matrix_dim]]; tile_size]]>(transp).map::<[[ [[f32; tile_size]]; matrix_dim]]>(grp::<tile_size>).map::<[[ [[ [[f32; tile_size]]; tile_size]]; matrix_dim/tile_size]]>(map::<[[ [[f32; tile_size]]; tile_size]]>(transp));

    //Berechnung der Äußeren Tiles und des Diagonal-Tiles
    //(row_of_tiles, rest) -> row_of_tiles for position of dia and peri_row, rest is for position of peri_col
    let splitted_row_of_tiles_and_rest: &uniq gpu.global ([[ [[ [[ [[f32; tile_size]]; tile_size]]; (matrix_dim / tile_size) ]]; 1]], [[ [[ [[ [[f32; tile_size]]; tile_size]]; (matrix_dim / tile_size)]]; matrix_dim/tile_size -it-1]]) =
                &uniq (*matrix_view)[..it..].1[..1..];
    //(dia, peri_row) in global
    let position_of_tile: &uniq gpu.global ([[ [[ [[f32; tile_size]]; tile_size]]; 1]], [[ [[ [[f32; tile_size]]; tile_size]]; matrix_dim/tile_size -it-1]])  =
                &uniq (*splitted_row_of_tiles_and_rest).0[0][..it..].1[..1..];
    let peri_row_global: &shrd gpu.global [[ [[ [[f32; tile_size]]; tile_size]]; matrix_dim/tile_size -it-1]] = &shrd (*position_of_tile).1;

    //peri_col in global TODO merken für innere Tiles: (*splitted_row_of_tiles_and_rest).1.transp[..it..].1[..1..].1 noch zurück transponieren?? -> inneres tranpose rückgängig machen
    let position_of_inner_tiles: &uniq gpu.global ([[ [[ [[ [[f32; tile_size]]; tile_size]]; matrix_dim/tile_size - it-1]]; 1]],  [[ [[ [[ [[f32; tile_size]]; tile_size]]; matrix_dim/tile_size - it-1]]; matrix_dim/tile_size - it-1]]) =
                &uniq (*splitted_row_of_tiles_and_rest).1.transp[..it..].1[..1..];

    //create shared views
    let peri_row_view: &uniq gpu.shared [[ [[f32; tile_size]]; tile_size]] = &uniq (*peri_row).to_view.grp::<tile_size>;//.map::<[[[f32; tile_size]; tile_size]; matrix_dim/tile_size - it-1]>(to_view.map::<[[f32; tile_size]; tile_size]>(to_view.map::<[f32; tile_size]>(to_view)));
    let peri_col_view: &uniq gpu.shared [[ [[f32; tile_size]]; tile_size]] = &uniq (*peri_col).to_view.grp::<tile_size>;//.map::<[[[f32; tile_size]; tile_size]; matrix_dim/tile_size - it-1]>(to_view.map::<[[f32; tile_size]; tile_size]>(to_view.map::<[f32; tile_size]>(to_view)));

    let peri_col_global: &shrd gpu.global [[ [[ [[f32; tile_size]]; tile_size]]; matrix_dim/tile_size - it-1]] = &shrd (*position_of_inner_tiles).0[0];

    sched(Y) block_y in grid {
        let peri_col_global_block_y: &shrd gpu.global [[ [[f32; tile_size]]; tile_size]] = &shrd (*peri_col_global)[[block_y]];

        sched(X) block_x in block_y{
            sched(Y) thread_y in block_x {
                sched(X) thread_x in thread_y {
                    //TODO 4. Dimension notwendig?
                    let peri_row_shared_block: &uniq gpu.shared f32 = &uniq (*peri_row_view)[[thread_y]][[thread_x]];
                    let peri_col_shared_block: &uniq gpu.shared f32 = &uniq (*peri_col_view)[[thread_y]][[thread_x]];
                    let peri_row_global_block: &shrd gpu.global f32 = &shrd (*peri_row_global)[[block_x]][[thread_y]][[thread_x]];
                    let peri_col_global_block: &shrd gpu.global f32 = &shrd (*peri_col_global_block_y)[[thread_y]][[thread_x]];

                    (*peri_row_shared_block) = (*peri_row_global_block);
                    (*peri_col_shared_block) = (*peri_col_global_block)
                }
            };
            sync
        }

    };
    let inner_tiles: &uniq gpu.global [[ [[ [[ [[f32; tile_size]]; tile_size]]; matrix_dim/tile_size - it-1]]; matrix_dim/tile_size - it-1]] = &uniq (*position_of_inner_tiles).1.transp;

    sched(Y) block_y in grid {
        sched(X) block_x in block_y  {
            sched(Y) thread_y in block_x {
                let peri_col_t: &shrd gpu.shared [[f32; tile_size]] = &shrd (*peri_col_view)[[thread_y]];

                sched(X) thread_x in thread_y{
                    let peri_row_t: &shrd gpu.shared [[f32; tile_size]] = &shrd (*peri_row_view).transp[[thread_x]];
                    let thread_element: &uniq gpu.global f32 = &uniq (*inner_tiles)[[block_y]][[block_x]][[thread_y]][[thread_x]];

                    let mut sum: f32 = 0.0f32;//(*peri_col_t)[0] * (*peri_row_t)[0];
                    for_nat i in 0..tile_size {
                        sum = sum + (*peri_col_t)[i] * (*peri_row_t)[i]
                    };
                    (*thread_element) = (*thread_element) - sum
                }
            }
        }
    }
}