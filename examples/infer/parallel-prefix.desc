/*
 * Naming stuff is hard:
 * - cpu_    prefix is memory in the cpu
 * - g_      prefix is global memory
 * - gi_     prefix is global memory inside the exec
 * - b_      prefix is for block memory
 * - shared_ prefix is shared memory inside a block
 * - view_   preifx(or suffix) is a view of the following
 * - t_      prefix is inside a parfor per thread
 */

fn prefix_scan<g_size: nat, b_size: nat, t_size: nat>(
    // TODO global fun params into same frame as top level declaration in body
    cpu_i_array: &uniq cpu.mem [i32; g_size * b_size * t_size],
    cpu_flag_array: &uniq cpu.mem [i32; g_size],
    cpu_agg_array: &uniq cpu.mem [i32; g_size],
    cpu_prefix_array: &uniq cpu.mem [i32; g_size]
) -[cpu.thread]-> () {
    let mut gpu = gpu_device(0);

    let mut g_i = gpu_alloc_copy(&uniq gpu, &shrd *cpu_i_array);
    let mut g_flags = gpu_alloc_copy(&uniq gpu, &shrd *cpu_flag_array);
    let mut g_aggs = gpu_alloc_copy(&uniq gpu, &shrd *cpu_agg_array);
    let mut g_prefixs = gpu_alloc_copy(&uniq gpu, &shrd *cpu_prefix_array);
    exec::<g_size, b_size>(
        &uniq gpu,
        (
            &uniq g_i, 
            &uniq g_flags,
            &uniq g_aggs,
            &uniq g_prefixs
        ),
        | grid: BlockGrp<g_size, ThreadGrp<b_size>>,
          input: (
              &uniq gpu.global [i32; g_size * b_size * t_size],
              &uniq gpu.global [i32; g_size],
              &uniq gpu.global [i32; g_size],
              &uniq gpu.global [i32; g_size]
          )
        | -[gpu.grid]-> () {
            // TODO deconstruction works
            let gi_i = input.0;
            let gi_flags = input.1;
            let gi_aggs = input.2;
            let gi_prefixs = input.3;
            let view_input = group_mut::<(b_size * t_size)>(to_view_mut(gi_i));
            let view_aggs = group_mut::<1>(to_view_mut(gi_aggs));
            let view_flags = group_mut::<1>(to_view_mut(gi_flags));
            // let view_flags = to_view_mut(gi_flags);
            let view_prefix = group_mut::<1>(to_view_mut(gi_prefixs));
            decl {
                let mut shared_input: [i32; (b_size * t_size)] @ gpu.shared;
                let mut shared_input_bkp: [i32; (b_size * t_size)] @ gpu.shared;
                // let mut tmp2: [i32; 1024 * 2] @ gpu.shared;
                let mut result_reduction: [i32; b_size] @ gpu.shared;
                let mut exclusive_prefix: [i32; 1] @ gpu.shared;
                let mut last_value: [i32; 1] @ gpu.shared
            } parfor block in grid 
                with b_input, b_agg, b_flag, b_prefix from view_input, view_aggs, view_flags, view_prefix {
                // Copy into shared
                let mut shared_input_view = group_mut::<t_size>(to_view_mut(& uniq shared_input));
                let mut shared_input_bkp_view = group_mut::<t_size>(to_view_mut(& uniq shared_input_bkp));
                let mut result_view = to_view_mut(&uniq result_reduction);
                let mut view_exclusive_prefix = to_view_mut(&uniq exclusive_prefix);
                let mut view_last_value = to_view_mut(&uniq last_value);
                let group_input = group_mut::<t_size>(b_input);
                parfor thread in block
                with t_shared_input, t_input, t_shared_input_bkp from
                    &uniq *shared_input_view, &uniq *group_input, &uniq * shared_input_bkp_view {
                    for_nat k in range(0, t_size) {
                        t_shared_input[k] = t_input[k]
                    };
                    for_nat k in range(0, t_size) {
                        t_shared_input_bkp[k] = t_input[k]
                    } 
                };

                parfor thread in block
                with t_shared_input, r from &uniq *shared_input_view, &uniq *result_view {
                    *r = 0;
                    for_nat k in range(0, t_size) {
                        *r = *r + t_shared_input[k]
                    } 
                };

                // borrowed from tree_reduce
                for_nat k in halved_range(b_size / 2) {
                   let split_ib = (split uniq 2*k (*result_view)).0;
                   let (active_half0, active_half1) = split uniq k (*split_ib);

                   parfor thread in split_thread_grp::<k, b_size, 1, 1>(block).0
                   with fst_half, snd_half from active_half0, active_half1 {
                       *fst_half = *fst_half + *snd_half
                   }
                };

                parfor thread in split_thread_grp::<1>(block).0
                with t_r, t_agg from &uniq *result_view, &uniq *b_agg {
                    *t_agg = *t_r
                };
                // Cheesy Threadfence
                parfor thread in split_thread_grp::<1>(block).0
                with t_flag from &uniq *b_flag {
                    *t_flag = 1
                };

                let curr_block_id_x = block_id_x();
                parfor thread in split_thread_grp::<1>(block).0
                with t_exclusive_prefix, t_flag, t_agg, t_prefix from
                &uniq *view_exclusive_prefix, &uniq *b_flag, &uniq *b_agg, &uniq *b_prefix {
                    if curr_block_id_x > 0 {
                        let mut not_done = true;
                        let mut endIndex = curr_block_id_x - 5;
                        if endIndex < 0 {
                            endIndex = 0
                        };
                        // TODO implement !done
                        while not_done {
                            *t_exclusive_prefix = 0;
                            let mut i = 1;
                            let mut flag = 0;
                            let mut agg = 0;
                            let mut prefix = 0;
                            let mut not_break_loop = true;
                            while i <= 5 && curr_block_id_x - i >= 0 && not_break_loop {
                                let raw_ptr_flag = to_raw_ptr(&uniq *t_flag);
                                let raw_ptr_flag_offset = offset_raw_ptr::<i32>(raw_ptr_flag, 0 - i);

                                let raw_ptr_agg = to_raw_ptr(&uniq *t_agg);
                                let raw_ptr_agg_offset = offset_raw_ptr::<i32>(raw_ptr_agg, 0 - i);

                                let raw_ptr_prefix = to_raw_ptr(&uniq *t_prefix);
                                let raw_ptr_prefix_offset = offset_raw_ptr::<i32>(raw_ptr_prefix, 0 - i);

                                unsafe {
                                    flag = *raw_ptr_flag_offset;
                                    agg = *raw_ptr_agg_offset;
                                    prefix = *raw_ptr_prefix_offset
                                };

                                if flag == 0 {
                                    not_break_loop = false
                                };
                                if flag == 1 {
                                    *t_exclusive_prefix = *t_exclusive_prefix + agg
                                };
                                if flag == 2 {
                                    *t_exclusive_prefix = *t_exclusive_prefix + prefix;
                                    not_break_loop = false;
                                    not_done = false
                                };
                                i = i - 1
                            }
                        }
                    }
                };
                parfor thread in split_thread_grp::<1>(block).0
                with t_r, t_prefix, t_exclusive_prefix from &uniq *result_view, &uniq *b_prefix, &shrd *view_exclusive_prefix  {
                    *t_prefix = *t_exclusive_prefix + *t_r
                };
                // Cheesy Threadfence
                parfor thread in split_thread_grp::<1>(block).0
                with t_flag from &uniq *b_flag {
                    *t_flag = 2
                };

                // upsweep::<b_size, t_size>(block, &uniq shared_input)
                // upsweep(block, &uniq shared_input);
                {
                    let foo = &uniq shared_input;
                    for_nat d in halved_range(b_size) <'a>{
                        let tmp_up_view = group_mut::<(b_size * t_size)/d, 'a, gpu.shared, (b_size * t_size), i32>(
                            to_view_mut(&uniq *foo));
                        parfor _ in split_thread_grp::<d>(block).0
                        with arr from tmp_up_view
                        { arr[(b_size * t_size)/d-1] = arr[(b_size * t_size)/d-1] + arr[b_size/d-1] }
                    }
                };
                let tmp_view2 = to_view_mut(&uniq shared_input);
                let tmp_last = (split uniq ((b_size * t_size) - 1) (*tmp_view2)).1;
                parfor _ in split_thread_grp::<1>(block).0
                with last from &uniq *tmp_last
                {
                    // *last = *t_last_bkp
                    *last = 0
                };
                // downsweep(block, &uniq shared_input);
                {
                    let foo = &uniq shared_input;
                    for_nat d in doubled_range(1, b_size) <'b>{
                        let tmp_down_view = group_mut::<(b_size * t_size) / d, 'b, gpu.shared, (b_size * t_size), i32>(
                            to_view_mut::<'b, gpu.shared, (b_size * t_size), i32 > (&'b uniq *foo));
                        parfor _ in split_thread_grp::<d, b_size, 1, 1> (block).0
                            with arr from tmp_down_view
                        {
                            let t = arr[b_size/d-1];
                            arr[b_size/d-1] = arr[(b_size * t_size)/d-1];
                            arr[(b_size * t_size)/d-1] = arr[(b_size * t_size)/d-1] + t
                        }
                    }
                };
                // end downsweep
                parfor thread in block
                with t_tmp, t_input, t_input_bkp from &uniq *shared_input_view, group_input, shared_input_bkp_view   {
                    // Workaround for *exclusive_prefix in 2 b_size lines
                    for_nat k in range(0, t_size) {
                        t_input[k] = t_tmp[k] + view_exclusive_prefix[0] + t_input_bkp[k]
                    } 
                }
            }
        }
    );
    copy_to_host(&shrd g_i, cpu_i_array);
    copy_to_host(&shrd g_flags, cpu_flag_array);
    copy_to_host(&shrd g_aggs, cpu_agg_array);
    copy_to_host(&shrd g_prefixs, cpu_prefix_array)
}

fn upsweep(
    thread_grp: ThreadGrp<b_size>,
    arr_ref: &uniq gpu.shared [i32; (b_size * t_size)]
) -[gpu.block]-> () <>{
    for_nat d in halved_range(1024) <'a>{
        let tmp_up_view = group_mut::<2048/d, 'a, gpu.shared, 2048, i32>(
            to_view_mut(&uniq *arr_ref));
        parfor _ in split_thread_grp::<d>(thread_grp).0
        with arr from tmp_up_view
        { arr[2048/d-1] = arr[2048/d-1] + arr[1024/d-1] }
    }
}

fn downsweep(
    block: ThreadGrp<1024>,
    arr_ref: &uniq gpu.shared [i32; 2048]
) -[gpu.block]-> () <>{
    for_nat d in doubled_range(1, 1024) <'b>{
        let tmp_down_view = group_mut::<2048 / d, 'b, gpu.shared, 2048, i32>(
            to_view_mut::<'b, gpu.shared, 2048, i32 > (&'b uniq *arr_ref));
        parfor _ in split_thread_grp::<d, 1024, 1, 1> (block).0
        with arr from tmp_down_view
        {
            let t = arr[1024/d-1];
            arr[1024/d-1] = arr[2048/d-1];
            arr[2048/d-1] = arr[2048/d-1] + t
        }
    }
}
