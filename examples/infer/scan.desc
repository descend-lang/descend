fn scan_inplace<m: nat, a: prv>(
    data: &a uniq cpu.mem [i32; m]
) -[t: cpu.thread]-> () <>{
    let mut accum = 0;
    for d in data <>{
        let next = *d + accum;
        *d = accum;
        accum = next
    }
}

fn upsweep<a: prv>(
    arr_ref: &a uniq gpu.shared [i32; 64]
) -[block: gpu.block<X<32>>]-> () {
    for_nat d in halved_range(32) {
// FIXME the next line uses d:nat but group_mut is defined via d:dty, which clashes
        let tmp_up_view = group_mut::<64/d>(to_view_mut(&uniq *arr_ref));
        par_branch split_exec x d block {
            active =>
                parfor _ in active
                with arr from tmp_up_view
                { arr[64/d-1] = arr[64/d-1] + arr[32/d-1] },
            inactive => { () }
        }
    }
}

fn downsweep_inplace_red_add<a: prv, d: nat>(
    arr: &a uniq gpu.shared [[i32; 64/d]]
) -[gt: gpu.thread]-> () <>{
    let t = arr[32/d-1];
    arr[32/d-1] = arr[64/d-1];
    arr[64/d-1] = arr[64/d-1] + t
}

fn downsweep<a: prv>(
    arr_ref: &a uniq gpu.shared [i32; 64]
) -[block: gpu.block<X<32>>]-> () <>{
    for_nat d in doubled_range(32) {
        let tmp_down_view = group_mut::<64 / d>(
            to_view_mut(&uniq *arr_ref));

        par_branch split_exec x d block {
            active =>
                parfor _ in active
                with arr from tmp_down_view {
                    let t = arr[32/d-1];
                    arr[32/d-1] = arr[64/d-1];
                    arr[64/d-1] = arr[64/d-1] + t
                },
            inactive => { () }
        }
    }
}

// blockDim.x == 32
// n == 256 * blockDim.x * 2
// gridDim.x == n / (blockDim.x * 2) == 256
fn scan<n: nat, gridDim: nat, a: prv, b: prv, c: prv>(
    ha_array: &a shrd cpu.mem [i32; n],
    h_output: &b uniq cpu.mem [i32; n],
    h_block_sums: &c uniq cpu.mem [i32; n/64]
) -[t: cpu.thread]-> () {
    let mut gpu = gpu_device(0);

    let a_array = gpu_alloc_copy(&uniq gpu, ha_array);
    let mut out_array = gpu_alloc_copy(&uniq gpu, &shrd *h_output);
    let mut block_sums = gpu_alloc_copy(&uniq gpu, &shrd *h_block_sums);

    exec::<gridDim, 32>(
        &uniq gpu,
        (&shrd a_array, &uniq out_grp, &uniq block_sums_grp),
        | inputs: (&shrd gpu.global [i32; n],
                  &uniq gpu.global [i32; n],
                  &uniq gpu.global [i32; gridDim])
        | -[grid: gpu.grid<X<gridDim>, X<32>>]-> () {
            let block_group = group::<64>(to_view(inputs.0));
            let out_grp = group_mut::<64>(to_view_mut(inputs.1));
            // n/64 == 256
            let block_sums_grp = group_mut::<1>(to_view_mut(inputs.2));

            decl {
                let mut tmp: [i32; 64] @ gpu.shared
            } parfor block in grid
            with ib, block_out, bsum from block_group, out_grp, block_sums_grp {
                {
                    let tmp_view = to_view_mut(&uniq tmp);
                    let tmp_halves = split uniq 32 (*tmp_view);
                    let input_halves = split shrd 32 (*ib);

                    // Copy to temporary shared memory storage
                    parfor _ in block
                    with s0, s1, d0, d1 from input_halves.0, input_halves.1, tmp_halves.0, tmp_halves.1
                    {
                        *d0 = *s0;
                        *d1 = *s1
                    }
                };

                upsweep(block, &uniq tmp);

                //
                // Clear last elemen and record block sum
                //
                {
                    let tmp_view2 = to_view_mut(&uniq tmp);
                    let tmp_last = (split uniq 63 (*tmp_view2)).1;
                    par_branch split_exec x 1 block {
                        active =>
                            parfor _ in active
                            with sum, last from bsum, tmp_last
                            {
                                *sum = *last;
                                *last = 0
                            },
                        inactive => { () }
                    }
                };

                downsweep>(block, &uniq tmp);

                {
                    let tmp_view3 = to_view_mut(&uniq tmp);
                    let tmp_halves3 = split uniq 32 (*tmp_view3);
                    // Copy results to global memory
                    let output_halves = split uniq 32 (*block_out);
                    parfor _ in block
                    with d0, d1, s0, s1 from output_halves.0, output_halves.1, tmp_halves3.0, tmp_halves3.1
                    {
                        *d0 = *s0;
                        *d1 = *s1
                    }
                }
            }
        }
    );

    copy_to_host(&shrd block_sums, &uniq *h_block_sums);
    scan_inplace::<gridDim>(&uniq *h_block_sums);
    copy_to_gpu(&uniq block_sums, &shrd *h_block_sums);

    exec::<gridDim, 64>(
        &uniq gpu,
        (&uniq out_array, &shrd block_sums),
        | inputs: (&uniq gpu.global [i32; n], &shrd gpu.global [i32; gridDim]) |
            -[grid: gpu.grid<X<gridDim>, X<64>>]-> () {
            let scanned_vals =
                group_mut::<64>(to_view_mut(inputs.0));
            let block_sums = group::<1>(to_view(inputs.1));

            parfor block in grid
            with scanned_vals_blocked, block_sum from scanned_vals, block_sums
            {
                parfor _ in block
                with scanned_val, sum from scanned_vals_blocked, block_sum
                {
                    *scanned_val = *scanned_val + *sum
                }
            }
        });

    copy_to_host(&shrd out_array, &uniq *h_output)
}
