fn reduce_shared_mem<n: nat, a: prv, b: prv>(
    ha_array: &a shrd cpu.heap [i32; n],
    h_output: &b uniq cpu.heap [i32; 64]
) -[cpu.thread]-> () {
    letprov <'r, 's, 'c, 'd, 'e, 'f, 'g, 'h, 'm> {
        let mut gpu: Gpu = gpu_device(0);

        let a_array: [i32; n] @ gpu.global =
            gpu_alloc::<'c, a, cpu.stack, cpu.heap, [i32; n]>(&'c uniq gpu, ha_array);
        let mut out_array: [i32; 64] @ gpu.global =
            gpu_alloc::<'c, 'm, cpu.stack, cpu.heap, [i32; 64]>(&'c uniq gpu, &'m shrd *h_output);
        let view_a: [[&'r shrd gpu.global i32; n]] =
            to_view::<'r, gpu.global, n, i32>(&'r shrd a_array);
        let view_out: [[[[&'m uniq gpu.global i32; 1]]; 64]] =
            group::<1, 64, &'m uniq gpu.global i32>(to_view_mut::<'m, gpu.global, 64, i32>(&'m uniq out_array));
        let block_group = group::<1024, n, &'r shrd gpu.global i32>(view_a);
        exec::<64, 1024, 'h, cpu.stack, <[[[[&'r shrd gpu.global i32; 1024]]; 64]], [[[[&'m uniq gpu.global i32; 1]]; 64]]>>(
            &'h uniq gpu,
            <block_group, view_out>,
            | grid: BlockGrp<64, ThreadGrp<1024>>,
              views: <[[[[&'r shrd gpu.global i32; 1024]]; 64]], [[[[&'m uniq gpu.global i32; 1]]; 64]]>| -[gpu.grid]-> () {
                let input = views.0;
                let output = views.1;
                let mut tmp: [i32; 1024] @ gpu.shared = shared_alloc::<[i32; 1024]>();
                for grid with <input, output, tmp> do
                    | block: ThreadGrp<1024>,
                      ib: [[&'r shrd gpu.global i32; 1024]],
                      out_elem: [[&'m uniq gpu.global i32; 1]],
                      mut tmpb: [i32; 1024] @ gpu.shared
                    | -[gpu.block]-> () {
                         let tmp_view: [[&'e uniq gpu.shared i32; 1024]] =
                            to_view_mut::<'e, gpu.shared, 1024, i32>(&'e uniq tmpb);
                         for block
                         with <ib, tmp_view>
                         do
                            |
                              inp: &'r shrd gpu.global i32 , tmp_in: &'e uniq gpu.shared i32
                            | -[gpu.thread]-> () {
                                 *tmp_in = *inp
                            };
                         for_nat k in halved_range(512) {
                             let active_halves = split_at::<k, 2*k, &'s uniq gpu.shared i32>(
                                split_at::<2*k, 1024, &'s uniq gpu.shared i32>(
                                    to_view_mut::<'s, gpu.shared, 1024, i32>(&'s uniq tmpb)).0);
                             for split_thread_grp::<k, 1024, 1, 1>(block).0
                             with active_halves
                             do
                                |
                                  a: &'s uniq gpu.shared i32, b: &'s uniq gpu.shared i32
                                | -[gpu.thread]-> () {
                                    *a = *a + *b
                                }
                         };
                         let tmp_res = split_at::<1, 1024, &'f uniq gpu.shared i32>(
                            to_view_mut::<'f, gpu.shared, 1024, i32>(&'f uniq tmpb)).0;
                         for split_thread_grp::<1, 1024, 1, 1>(block).0
                         with <out_elem, tmp_res>
                         do
                            |
                              out_elem: &'m uniq gpu.global i32 , tmp_val: &'f uniq gpu.shared i32
                            | -[gpu.thread]-> () {
                                *out_elem = *tmp_val
                            }
                     }
            }
        );
        // Todo
        //  There is no check for n == 64 (which is NOT the case). Therefore it is wrong to specify
        //  [i32; n] as the array type. However, this still type checks.
        copy_to_host::<'g, b, cpu.heap, [i32; 64]>(&'g shrd out_array, h_output)
    }
}