fn bfs<n:nat, m:nat, a: prv, b: prv, k:prv, l:prv>(
    h_nodes: &a shrd cpu.heap [(i32, i32); n],
    h_edges: &b shrd cpu.heap [i32; m],
    h_changes: &k uniq cpu.heap [(bool, bool, bool, i32); n],
    h_stop: &l uniq cpu.heap bool
) -[cpu.thread]-> () {
    letprov<'c, 'd, 'e, 'f, 'r, 's, 'g, 'h, 'i, 'o, 'p, 't, 'q, 'j, 'u, 'v>{

        let gpu: Gpu = gpu_device(0);

        let nodes: [(i32, i32); n] @ gpu.global = 
            gpu_alloc::<'c, 'd, cpu.stack, cpu.heap, [(i32, i32); n]>(&'c uniq gpu, &'d shrd *h_nodes);

        let edges: [i32; m] @ gpu.global =
            gpu_alloc::<'e, 'f, cpu.stack, cpu.heap, [i32; m]>(&'e uniq gpu, &'f shrd *h_edges);

        let nodes_view: [[ &'r shrd gpu.global (i32, i32); n]] =
            to_view::<'r, gpu.global, n, (i32, i32)>(&'r shrd nodes);

        let edges_view: [[ &'s shrd gpu.global i32; m ]] =
            to_view::<'s, gpu.global, m, i32>(&'s shrd edges);

        // TODO this array is now handed to the function...
        // (mask, updating mask, visited, cost)
        // let mut h_changes: [(bool, bool, bool, i32); n] @ cpu.heap = [(false, false, false, -1)]; 
        // node 0 is root
        // h_changes[0].0 = true;
        // h_changes[0].2 = true;
        // h_changes[0].3 = 0;

        let mut d_changes: [(bool, bool, bool, i32); n] @ gpu.global = 
            gpu_alloc::<'g, 'h, cpu.stack, cpu.heap, [(bool, bool, bool, i32); n]>(&'g uniq gpu, &'h shrd *h_changes);

        let view_changes: [[ &'i uniq gpu.global (bool, bool, bool, i32); n]] =
            to_view_mut::<'i, gpu.global, n, (bool, bool, bool, i32)>(&'i uniq d_changes);
        
        let zipped_nodes_changes: [[ <&'r shrd gpu.global (i32, i32),  &'i uniq gpu.global (bool, bool, bool, i32) >; n ]] =
            zip::<n, &'r shrd gpu.global (i32, i32), &'i uniq gpu.global (bool, bool, bool, i32) >(nodes_view, view_changes);


        
        let grouped_nodes_changes: [[ [[ <&'r shrd gpu.global (i32, i32),  &'i uniq gpu.global (bool, bool, bool, i32) >; 1024 ]]; n/1024]] =
            group::<1024, n, <&'r shrd gpu.global (i32, i32),  &'i uniq gpu.global (bool, bool, bool, i32)> >(zipped_nodes_changes);


        // let mut h_stop: bool @ cpu.heap = true;
        let mut d_stop: bool @ gpu.global =
            gpu_alloc::<'o, 'p, cpu.stack, cpu.heap, bool>(&'o uniq gpu, &'p shrd *h_stop);
        copy_to_host::<'u, l, bool>(&'u shrd d_stop, h_stop);

        while h_stop {

            *h_stop = false;
            copy_to_gpu::<'t, 'q, bool>(&'t uniq h_stop, &'q shrd d_stop); // missing prov

            //kernel 1
            exec::< 64 , 1024, 'j, cpu.stack, [[ [[ <&'r shrd gpu.global (i32, i32),  &'i uniq gpu.global (bool, bool, bool, i32) >; 1024 ]]; 64]]>(
                &'h uniq gpu,
                grouped_nodes_changes,
                | grid: Grid<Block<Thread, 1024>, 64>,
                  input: [[ [[ <&'r shrd gpu.global (i32, i32),  &'i uniq gpu.global (bool, bool, bool, i32) >; 1024 ]]; 64]]
                | -[gpu.grid]-> () {
                      for grid with <input> do
                        | block: Block<Thread, 1024>,
                          ib: [[ <&'r shrd gpu.global (i32, i32),  &'i uniq gpu.global (bool, bool, bool, i32) >; 1024 ]] 
                        | -[gpu.block]-> () {

                            for block with <ib> do 
                                | thread: Thread,
                                  inp: <&'r shrd gpu.global (i32, i32),  &'i uniq gpu.global (bool, bool, bool, i32)> 
                                | -[gpu.thread]-> () {

                                    // need to access edges_view and view_changes
                                    // this is exactly where bounds checking is needed
                                    
                                    
                                    *inp.1.0 = true; // while real kernel is not used
                                    // mask
                                    /*
                                    if *inp.1.0 { // TODO if will not be implemented, but if_else

                                        *inp.1.0 = false;
                                        let node_start = *inp.0.0;
                                        let no_of_edges = *inp.0.1;
                                        for i in node_start..node_start+*no_of_edges {

                                            let id: i32 = *edges_view[i];

                                            // visited
                                            if !*view_changes[i].2 {

                                                // cost = input cost + 1 
                                                *view_changes[i].3 = *inp.1.3 + 1;
                                                *view_changes[i].1 = true; // updating mask 

                                            } else {
                                                ()
                                            }

                                        }

                                    } else {
                                        ()
                                    }
                                    */
                                    
                                  };

                          };

                  }
            );

            //kernel 2 
            exec::<64, 1024, 'j, cpu.stack, [[ [[ <&'r shrd gpu.global (i32, i32),  &'i uniq gpu.global (bool, bool, bool, i32) >; 1024 ]]; 64]]>(
                &'h uniq gpu,
                grouped_nodes_changes,
                | grid: Grid<Block<Thread, 1024>, 64>,
                  input: [[ [[ <&'r shrd gpu.global (i32, i32),  &'i uniq gpu.global (bool, bool, bool, i32) >; 1024 ]]; 64]]
                | -[gpu.grid]-> () {

                      for grid with input do
                        | block: Block<Thread, 1024>,
                          ib: [[ <&'r shrd gpu.global (i32, i32),  &'i uniq gpu.global (bool, bool, bool, i32) >; 1024 ]] 
                        | -[gpu.block]-> () {

                            for block with ib do 
                                | thread: Thread,
                                  inp: <&'r shrd gpu.global (i32, i32),  &'i uniq gpu.global (bool, bool, bool, i32) > 
                                | -[gpu.thread]-> () {
                                    
                                    // can I access d_stop?

                                    //updating mask
                                    if *inp.1.1 {
                                        *inp.1.0 = true; // mask
                                        *inp.1.2 = true; // visited
                                        d_stop = true; //  does not work probably // TODO atomic set 
                                        *inp.1.1 = false; //updating mask
                                    } else {
                                        ()
                                    }


                                  };

                          };

                  }
            );

            
            copy_to_host::<'u, 'v, bool>(&'u shrd d_stop,&'v uniq h_stop);

        }


    }
    
}