fn bfs<n:nat, m:nat, a: prv, b: prv>(
    h_nodes: &a shrd cpu.heap [(i32, i32); n],
    h_edges: &b shrd cpu.heap [i32; m]
) -[cpu.thread]-> () {
    letprov<'c, 'd, 'e, 'f>{

        let gpu: Gpu = gpu_device(0);

        let nodes: [(i32, i32); n] @ gpu.global = 
        gpu_alloc::<'c, 'd, cpu.stack, cpu.stack, [i32; n]>(&'c uniq gpu, &'d shrd *h_nodes);

        let edges: [i32; m] @ gpu.global =
        gpu_alloc::<'e, 'f, cpu.stack, cpu.stack, [i32; m]>(&'e uniq gpu, &'f shrd *h_edges);

        let nodes_view: [[ &'r shrd gpu.global (i32, i32); n]] =
            to_view::<'r, gpu.global, n, (i32, i32)>(&'r shrd nodes);

        let edges_view: [[ &'s shrd gpu.global i32; m ]] =
            to_view::<'s, gpu.global, m, i32>('s shrd edges);

        
        // let mut h_mask: [bool; n] @ cpu.heap = [false; n];
        // let mut h_updating_mask: [bool; n] @ cpu.heap = [false; n];
        // let mut h_visited: [bool; n] @ cpu.heap = [false; n];
        // let mut h_cost: : [i32; n] @ cpu.heap = [0; n];

        // let mut mask: [bool; n] @ gpu.global = 
        //     gpu_alloc<'g, 'h, cpu.stack, cpu.stack, [bool; n]>(&'g uniq gpu, &'h shrd *h_mask);

        // let mut updating_mask: [bool; n] @ gpu.global =
        //     gpu_alloc<'i, 'j, cpu.stack, cpu.stack, [i32; n]>(&'i uniq gpu, &'j shrd *h_updating_mask);

        // let mut visited: [bool; n] @ gpu.global =
        //     gpu_alloc<'k, 'l, cpu.stack, cpu.stack, [i32; n]>(&'k uniq gpu, &'l shrd *h_updating_mask);

        // let mut cost: [i32; n] @ gpu.global =
        //     gpu_alloc<'m, 'n, cpu.stack, cpu.stack, [i32; n]>(&'m uniq gpu, &'n shrd *h_updating_mask);




        // mask, updating mask, visited, cost
        let mut h_changes: [(bool, bool, bool, i32); n] @ cpu.heap = [(false, false, false, -1); n]; // Todo create_array() s. cuda_examples vec add

        let mut d_changes: [(bool, bool, bool, i32); n] @ gpu.heap = 
            gpu_alloc::<'g, 'h, cpu.stack, cpu.stack, [(bool, bool, bool, i32); n]>(&'g uniq gpu, &'h shrd h_changes);

        let view_changes: [[ &'i uniq gpu.global (bool, bool, bool, i32) ]] =
            to_view_mut::<'i, gpu.global, n, {bool, bool, bool, i32}>(&i uniq d_changes);


        
        let zipped_nodes_changes: [[ {'r shrd gpu.global {i32, i32},  &'i uniq gpu.global {bool, bool, bool, i32} }; n ]] =
            zip::<n, &'r shrd gpu.global {i32, i32}, &'i uniq gpu.global {bool, bool, bool, i32} }>(nodes_view, view_changes);


        let grouped_nodes_changes [[ [[ {'r shrd gpu.global {i32, i32},  &'i uniq gpu.global {bool, bool, bool, i32} }; 1024 ]]; n/1024]] =
            group::<1024, n, {'r shrd gpu.global {i32, i32},  &'i uniq gpu.global {bool, bool, bool, i32} }>(zipped_nodes_changes);


        let mut h_stop: bool @ cpu.heap = true;
        let mut d_stop: bool @ gpu.global =
            gpu_alloc<'o, 'p, cpu.stack, cpu.stack, bool>(&'o uniq gpu, &'f shrd *h_stop);

        while stop {

            h_stop = false;
            copy_to_gpu<'q, , bool>(h_stop, &'q shrd d_stop); // missing prov

            //kernel 1
            exec<n/1024, 1024, 'j, cpu.stack, [[ {'r shrd gpu.global {i32, i32},  &'i uniq gpu.global {bool, bool, bool, i32} }; 1024 ]], n/1024>(
                &'h uniq gpu,
                grouped_nodes_changes,
                | grid: Grid<Block<Thread, 1024>, n/1024>,
                  input: [[ [[ {'r shrd gpu.global {i32, i32},  &'i uniq gpu.global {bool, bool, bool, i32} }; 1024 ]]; n/1024]]| -[gpu]-> () {

                      for grid with input do
                        | block: Blocl<Thread, 1024>,
                          ib: [[ {'r shrd gpu.global {i32, i32},  &'i uniq gpu.global {bool, bool, bool, i32} }; 1024 ]] | -[gpu.group]-> () {

                            for block with ib do 
                                | thread: Thread,
                                  inp: {'r shrd gpu.global {i32, i32},  &'i uniq gpu.global {bool, bool, bool, i32} } | -[gpu.thread]-> () {

                                    // need to access edges_view and view_changes
                                    // this is exactly where bounds checking is needed
                                    
                                    // mask
                                    if *inp.1.0 { // TODO if will not be implemented, but if_else

                                        *inp.1.0 = false;
                                        let node_start = *inp.0.0;
                                        let no_of_edges = *inp.0.1;
                                        for i in node_start..node_start+*no_of_edges {

                                            let id: i32 = *edges_view[i];

                                            // visited
                                            if !*view_changes[i].2 {

                                                // cost = input cost + 1 
                                                *view_changes[i].3 = *inp.1.3 + 1;
                                                *view_changes[i].1 = true; // updating mask 

                                            } else {
                                                ()
                                            }

                                        }

                                    } else {
                                        ()
                                    }


                                  }

                          }

                  }
            );

            //kernel 2 
            exec<n/1024, 1024, 'j, cpu.stack, [[ {'r shrd gpu.global {i32, i32},  &'i uniq gpu.global {bool, bool, bool, i32} }; 1024 ]], n/1024>(
                &'h uniq gpu,
                grouped_nodes_changes,
                | grid: Grid<Block<Thread, 1024>, n/1024>,
                  input: [[ [[ {'r shrd gpu.global {i32, i32},  &'i uniq gpu.global {bool, bool, bool, i32} }; 1024 ]]; n/1024]]| -[gpu]-> () {

                      for grid with input do
                        | block: Blocl<Thread, 1024>,
                          ib: [[ {'r shrd gpu.global {i32, i32},  &'i uniq gpu.global {bool, bool, bool, i32} }; 1024 ]] | -[gpu.group]-> () {

                            for block with ib do 
                                | thread: Thread,
                                  inp: {'r shrd gpu.global {i32, i32},  &'i uniq gpu.global {bool, bool, bool, i32} } | -[gpu.thread]-> () {
                                    
                                    // can I access d_stop?

                                    //updating mask
                                    if *inp.1.1 {
                                        *inp.1.0 = true; // mask
                                        *inp.1.2 = true; // visited
                                        d_stop = true; //  does not work probably // TODO atomic set 
                                        *inp.1.1 = false; //updating mask
                                    }


                                  }

                          }

                  }
            );

            
            copy_to_host<'r, , bool>(&'r shrd d_stop, h_stop);

        }


    }
    
}